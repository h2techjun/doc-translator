import { Readable, PassThrough } from 'stream';
import { BaseTranslationStrategy } from './base-strategy';
import PizZip from 'pizzip';
import { DOMParser, XMLSerializer } from '@xmldom/xmldom';
import { ContentAnalyzer } from '../../ai/content-analyzer';

/**
 * ğŸ“ ì›Œë“œ ë¬¸ì„œ ë²ˆì—­ ì „ëµ (PizZip + XML í•¸ë“¤ë§ - Paragraph Mode)
 * 
 * ğŸ¯ ëª©ì  (Purpose):
 * Word ë¬¸ì„œì˜ í…ìŠ¤íŠ¸ë¥¼ 'ë¬¸ë‹¨(Paragraph)' ë‹¨ìœ„ë¡œ ë³‘í•©í•˜ì—¬ ë²ˆì—­í•¨ìœ¼ë¡œì¨
 * ë¬¸ë§¥ ë‹¨ì ˆ ë° ì”ì—¬ í…ìŠ¤íŠ¸(Residual Text) ë¬¸ì œë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ í•´ê²°í•©ë‹ˆë‹¤.
 * 
 * âš ï¸ Trade-off:
 * ë¬¸ë‹¨ ë‚´ì˜ ìŠ¤íƒ€ì¼(ê¸€ì ìƒ‰, êµµê¸° ë“±)ì´ í˜¼ì¬ëœ ê²½ìš°, 
 * ë²ˆì—­ í›„ì—ëŠ” ë¬¸ë‹¨ì˜ **ì²« ë²ˆì§¸ ìŠ¤íƒ€ì¼**ë¡œ í†µì¼ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
 * í•˜ì§€ë§Œ ì´ëŠ” "ë²ˆì—­ë˜ì§€ ì•Šì€ ì›ë¬¸ì´ ë‚¨ëŠ” ê²ƒ"ë³´ë‹¤ í›¨ì”¬ ë‚˜ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.
 */
export class DocxTranslationStrategy extends BaseTranslationStrategy {
    async translate(fileBuffer: Buffer, targetLang: string): Promise<Buffer> {
        console.log(`[DocxStrategy] ğŸ“ Word ë²ˆì—­ ì‹œì‘ (Paragraph Mode | ëª©í‘œ: ${targetLang})`);

        // 1ï¸âƒ£ DOCX -> XML ì¶”ì¶œ
        const zip = new PizZip(fileBuffer);
        const xmlContent = zip.file('word/document.xml')?.asText();
        if (!xmlContent) {
            throw new Error('Word ë¬¸ì„œ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ (document.xml ëˆ„ë½)');
        }

        // 2ï¸âƒ£ XML íŒŒì‹±
        const parser = new DOMParser();
        const xmlDoc = parser.parseFromString(xmlContent, 'application/xml');

        // 3ï¸âƒ£ ë¬¸ë‹¨(Paragraph) ë‹¨ìœ„ ë°ì´í„° ì¶”ì¶œ
        const paragraphs = xmlDoc.getElementsByTagName('w:p');
        const batchRequests: { fullText: string; textNodes: Element[] }[] = [];

        // ê° ë¬¸ë‹¨ì„ ìˆœíšŒí•˜ë©° í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        for (let i = 0; i < paragraphs.length; i++) {
            const p = paragraphs[i];
            const textNodes = Array.from(p.getElementsByTagName('w:t'));

            if (textNodes.length === 0) continue;

            // ë¬¸ë‹¨ ë‚´ í…ìŠ¤íŠ¸ ë³‘í•© (Run Aggregation)
            // ì˜ˆ: ["ì œ", "1", "ì¡°"] -> "ì œ1ì¡°"
            const fullText = textNodes.map(node => node.textContent || '').join('');

            if (fullText.trim().length > 1) { // 1ê¸€ì ì´ìƒì˜ ìœ ì˜ë¯¸í•œ í…ìŠ¤íŠ¸ë§Œ
                batchRequests.push({ fullText, textNodes });
            }
        }

        console.log(`  âœ… ë²ˆì—­ ëŒ€ìƒ ë¬¸ë‹¨ ë°œê²¬: ${batchRequests.length}ê°œ`);

        // 4ï¸âƒ£ ëª¨ë¸ ë¶„ì„ (ì²« 20ê°œ ë¬¸ë‹¨ ìƒ˜í”Œë§)
        if (batchRequests.length > 0) {
            const sampleText = batchRequests.slice(0, 20).map(r => r.fullText).join("\n");
            const analyzer = new ContentAnalyzer(process.env.GEMINI_API_KEY!);

            console.log("  ğŸ•µï¸ ë¬¸ì„œ ìœ í˜• ë¶„ì„ ì¤‘...");
            const analysis = await analyzer.analyzeAndRecommend(sampleText);
            console.log(`  ğŸ” ë¶„ì„ ê²°ê³¼: [${analysis.docType.toUpperCase()}] - ${analysis.reason}`);
            console.log(`  ğŸ¤– ì¶”ì²œ ëª¨ë¸: ${analysis.recommendedModel.name}`);

            this.setModel(analysis.recommendedModel);
        }

        // 5ï¸âƒ£ ë°°ì¹˜ ì²˜ë¦¬ ì¤€ë¹„
        const MAX_BATCH_CHARS = 15000; // ë¬¸ë§¥ì´ ê¸¸ì–´ì§€ë¯€ë¡œ ì¡°ê¸ˆ ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡ìŒ
        const MAX_BATCH_SEGMENTS = 100; // ë¬¸ë‹¨ ë‹¨ìœ„ì´ë¯€ë¡œ ê°œìˆ˜ë¥¼ ì¤„ì„

        const batches: { texts: string[]; requestIndices: number[] }[] = [];
        let currentBatchTexts: string[] = [];
        let currentBatchIndices: number[] = [];
        let currentBatchLength = 0;

        for (let i = 0; i < batchRequests.length; i++) {
            const text = batchRequests[i].fullText;

            if (currentBatchTexts.length > 0 &&
                (currentBatchLength + text.length > MAX_BATCH_CHARS || currentBatchTexts.length >= MAX_BATCH_SEGMENTS)) {

                batches.push({ texts: currentBatchTexts, requestIndices: currentBatchIndices });
                currentBatchTexts = [];
                currentBatchIndices = [];
                currentBatchLength = 0;
            }

            currentBatchTexts.push(text);
            currentBatchIndices.push(i);
            currentBatchLength += text.length;
        }

        if (currentBatchTexts.length > 0) {
            batches.push({ texts: currentBatchTexts, requestIndices: currentBatchIndices });
        }

        console.log(`  ğŸ“Š ë°°ì¹˜ ìµœì í™”: ì´ ${batches.length}ê°œ ë°°ì¹˜ (ë¬¸ë‹¨ ${batchRequests.length}ê°œ)`);

        // 6ï¸âƒ£ ë²ˆì—­ ì‹¤í–‰ ë° ê²°ê³¼ ì£¼ì…
        for (let i = 0; i < batches.length; i++) {
            const { texts, requestIndices } = batches[i];

            // Throttling
            const delay = this.currentModelSpec.throttleDelayMs;
            if (i > 0 && delay > 0) {
                await new Promise(resolve => setTimeout(resolve, delay));
            }

            console.log(`  ğŸ”¬ Processing Batch ${i + 1}/${batches.length} (${texts.length} paragraphs)`);

            // ë²ˆì—­ í˜¸ì¶œ
            const translatedBatch = await this.translateBatch(texts, targetLang);

            // ê²°ê³¼ ì£¼ì… (Logic Check Re-injection)
            translatedBatch.forEach((translatedText, batchIndex) => {
                const originalRequestIdx = requestIndices[batchIndex];
                const { textNodes } = batchRequests[originalRequestIdx];

                // ğŸŒŸ í•µì‹¬ ë¡œì§: ì²« ë²ˆì§¸ ë…¸ë“œì— ëª°ì•„ë„£ê³  ë‚˜ë¨¸ì§€ëŠ” ë¹„ìš´ë‹¤.
                if (textNodes.length > 0) {
                    // 1. ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ë…¸ë“œì— ë²ˆì—­ë³¸ ì „ì²´ ì‚½ì…
                    textNodes[0].textContent = translatedText;

                    // 2. ë‚˜ë¨¸ì§€ ë…¸ë“œëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬ (ì‚­ì œí•˜ë©´ ì•ˆë¨, XML êµ¬ì¡° ìœ ì§€)
                    for (let k = 1; k < textNodes.length; k++) {
                        textNodes[k].textContent = "";
                    }
                }
            });
        }

        // 7ï¸âƒ£ XML ì¬ì¡°ë¦½ ë° ë°˜í™˜
        const serializer = new XMLSerializer();
        const newXmlContent = serializer.serializeToString(xmlDoc);
        zip.file('word/document.xml', newXmlContent);

        const resultBuffer = zip.generate({ type: 'nodebuffer' });
        console.log(`  âœ… Word ë²ˆì—­ ì™„ë£Œ (ì¶œë ¥: ${resultBuffer.length} bytes)`);

        return resultBuffer;
    }
}
