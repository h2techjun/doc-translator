
import PizZip from "pizzip";
import { DOMParser, XMLSerializer } from "@xmldom/xmldom";
import { translateText } from "@/lib/ai/gemini";

/**
 * ğŸ“„ DOCX ë¬¸ì„œ ë²ˆì—­ê¸° (ë¬¸ë‹¨ ë‹¨ìœ„ ì²˜ë¦¬)
 * 
 * ë¬¸ë‹¨(<w:p>)ì„ ê¸°ë³¸ ë‹¨ìœ„ë¡œ í•˜ì—¬ ë²ˆì—­í•˜ë¯€ë¡œ ë¬¸ë§¥ì´ ìœ ì§€ë©ë‹ˆë‹¤.
 */
export class DocxTranslator {
    private buffer: Buffer;

    constructor(buffer: Buffer) {
        this.buffer = buffer;
    }

    /**
     * ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì •
     */
    private estimateTokens(text: string): number {
        if (/[\u3131-\uD79D]/.test(text)) {
            return text.length * 2;
        }
        return text.split(/\s+/).length * 1.3;
    }

    /**
     * ë¬¸ë‹¨ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ì¶”ì¶œ
     */
    private extractParagraphText(paragraph: Element): string {
        const textNodes = paragraph.getElementsByTagName("w:t");
        let fullText = "";
        for (let i = 0; i < textNodes.length; i++) {
            fullText += textNodes[i].textContent || "";
        }
        return fullText;
    }

    /**
     * ë¬¸ë‹¨ì— ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ì ìš©
     */
    private applyTranslationToParagraph(paragraph: Element, translatedText: string): void {
        const textNodes = paragraph.getElementsByTagName("w:t");

        if (textNodes.length === 0) return;

        // ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ë…¸ë“œì— ì „ì²´ ë²ˆì—­ ê²°ê³¼ë¥¼ ë„£ê³ , ë‚˜ë¨¸ì§€ëŠ” ë¹„ì›€
        // (ì„œì‹ ìœ ì§€ë¥¼ ìœ„í•´ ì²« ë²ˆì§¸ ë…¸ë“œë§Œ ì‚¬ìš©)
        textNodes[0].textContent = translatedText;

        for (let i = 1; i < textNodes.length; i++) {
            textNodes[i].textContent = "";
        }
    }

    /**
     * ë¬¸ë‹¨ ê¸°ë°˜ ì²­í¬ ìƒì„± (ë¬¸ë‹¨ì€ ì ˆëŒ€ ìª¼ê°œì§€ ì•ŠìŒ)
     */
    private createParagraphChunks(
        paragraphs: { element: Element; text: string; index: number }[],
        maxTokensPerChunk: number = 2000
    ): { element: Element; text: string; index: number }[][] {
        const chunks: { element: Element; text: string; index: number }[][] = [];
        let currentChunk: { element: Element; text: string; index: number }[] = [];
        let currentTokens = 0;

        for (const para of paragraphs) {
            const paraTokens = this.estimateTokens(para.text);

            // ë‹¨ì¼ ë¬¸ë‹¨ì´ ë„ˆë¬´ í¬ë©´ ë³„ë„ ì²­í¬ë¡œ
            if (paraTokens > maxTokensPerChunk) {
                if (currentChunk.length > 0) {
                    chunks.push(currentChunk);
                    currentChunk = [];
                    currentTokens = 0;
                }
                chunks.push([para]);
                continue;
            }

            // í˜„ì¬ ì²­í¬ì— ì¶”ê°€í•˜ë©´ ì œí•œ ì´ˆê³¼
            if (currentTokens + paraTokens > maxTokensPerChunk && currentChunk.length > 0) {
                chunks.push(currentChunk);
                currentChunk = [para];
                currentTokens = paraTokens;
            } else {
                currentChunk.push(para);
                currentTokens += paraTokens;
            }
        }

        if (currentChunk.length > 0) {
            chunks.push(currentChunk);
        }

        return chunks;
    }

    async translate(targetLang: string): Promise<Buffer> {
        console.log("â¡ï¸ Loading DOCX...");
        const zip = new PizZip(this.buffer);

        const xmlContent = zip.file("word/document.xml")?.asText();
        if (!xmlContent) {
            throw new Error("Invalid DOCX: word/document.xml not found");
        }

        const doc = new DOMParser().parseFromString(xmlContent, "text/xml");
        const paragraphNodes = doc.getElementsByTagName("w:p");

        console.log(`â¡ï¸ Found ${paragraphNodes.length} paragraphs.`);

        // ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        const paragraphs: { element: Element; text: string; index: number }[] = [];

        for (let i = 0; i < paragraphNodes.length; i++) {
            const para = paragraphNodes[i] as Element;
            const text = this.extractParagraphText(para);

            if (text.trim().length > 0) {
                paragraphs.push({ element: para, text, index: i });
            }
        }

        if (paragraphs.length === 0) {
            console.log("âš ï¸ No text found in document.");
            return this.buffer;
        }

        console.log(`â¡ï¸ Translating ${paragraphs.length} paragraphs...`);

        // ë¬¸ë‹¨ ê¸°ë°˜ ì²­í¬ ìƒì„±
        const chunks = this.createParagraphChunks(paragraphs, 2000);
        console.log(`â¡ï¸ Created ${chunks.length} paragraph-based chunks`);

        for (let chunkIdx = 0; chunkIdx < chunks.length; chunkIdx++) {
            const chunk = chunks[chunkIdx];
            const sourceTexts = chunk.map(p => p.text);

            console.log(`   Processing chunk ${chunkIdx + 1}/${chunks.length} (${chunk.length} paragraphs)...`);

            try {
                const prompt = `
You are a professional document translator.
Translate the following JSON array of paragraphs into "${targetLang}" language.
Each element is a complete paragraph. Maintain paragraph structure and meaning.
IMPORTANT: Return ONLY a raw JSON array of strings. No markdown, no explanations.
The output array must have exactly the same number of elements as the input.

Input JSON:
${JSON.stringify(sourceTexts)}
`;

                const rawResponse = await translateText(prompt, targetLang);
                const cleanedJson = rawResponse.replace(/```json/g, '').replace(/```/g, '').trim();

                let translatedArray: string[] = [];
                try {
                    translatedArray = JSON.parse(cleanedJson);
                } catch (jsonError) {
                    console.error("JSON Parse Error:", cleanedJson.substring(0, 300));
                    throw new Error("Failed to parse JSON");
                }

                if (!Array.isArray(translatedArray)) {
                    throw new Error("Response is not an array");
                }

                // ë¬¸ë‹¨ì— ë²ˆì—­ ì ìš©
                chunk.forEach((para, idx) => {
                    const translated = translatedArray[idx];
                    if (translated) {
                        this.applyTranslationToParagraph(para.element, translated);
                    }
                });

            } catch (err: any) {
                console.error(`Chunk ${chunkIdx + 1} error:`, err.message);

                // ê°œë³„ ë¬¸ë‹¨ ì¬ì‹œë„
                console.log(`   ğŸ”„ Retrying paragraphs individually...`);

                for (const para of chunk) {
                    try {
                        const translated = await translateText(para.text, targetLang);
                        this.applyTranslationToParagraph(para.element, translated);
                    } catch (retryErr) {
                        console.error(`      âŒ Failed for paragraph ${para.index}`);
                        // ì›ë¬¸ ìœ ì§€ (ì´ë¯¸ elementì— ìˆìŒ)
                    }
                }
            }
        }

        const newXml = new XMLSerializer().serializeToString(doc);
        zip.file("word/document.xml", newXml);

        return zip.generate({ type: "nodebuffer" });
    }
}
